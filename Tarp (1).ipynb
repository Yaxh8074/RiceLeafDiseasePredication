{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "8KdPbwdYdzRy",
    "outputId": "92c34d09-ad2d-4467-b27b-9e8e11c90dc4"
   },
   "outputs": [],
   "source": [
    "# !mkdir -p ~/.kaggle\n",
    "# !mv kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# !kaggle datasets download -d trumanrase/rice-leaf-diseases -p ./data --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5LsCw139Zpdi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5XdKX7i7bEyS"
   },
   "outputs": [],
   "source": [
    "class Cfg:\n",
    "  data_root = \"./data/rice_disease_val_test\"\n",
    "  img_size = 224\n",
    "  batch_size = 32\n",
    "  num_workers = 0\n",
    "  epochs = 20\n",
    "  lr = 1e-3\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "cfg = Cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GweHeeq-bHPA"
   },
   "outputs": [],
   "source": [
    "def build_transforms(img_size):\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return train_tf, val_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R94xWfA4bJkE",
    "outputId": "6f9a63b7-6cf2-4dd6-cdb0-08228e8891ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes : ['bacterial_leaf_blight', 'bacterial_leaf_streak', 'bacterial_panicle_blight', 'blast', 'brown_spot', 'dead_heart', 'downy_mildew', 'hispa', 'normal', 'rice_sheath_blight', 'smut', 'tungro']\n"
     ]
    }
   ],
   "source": [
    "def build_dataloaders(data_root, img_size, batch_size, workers=0):\n",
    "    train_tf, val_tf = build_transforms(img_size)\n",
    "    train_ds = datasets.ImageFolder(os.path.join(data_root,\"train\"), transform=train_tf)\n",
    "    val_ds   = datasets.ImageFolder(os.path.join(data_root,\"val\"),   transform=val_tf)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "    return train_loader, val_loader, train_ds.classes\n",
    "\n",
    "train_loader, val_loader, class_names = build_dataloaders(cfg.data_root, cfg.img_size, cfg.batch_size, cfg.num_workers)\n",
    "cfg.num_classes = len(class_names)\n",
    "print(f\"Classes : {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQoXOzb7bTrJ",
    "outputId": "f7950ea4-6615-4ddd-edb1-b3f4fb80804c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 2,352,216\n",
      "Trainable parameters: 2,352,216\n",
      "Model size: 8.97 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import mobilenet_v3_small, mobilenet_v3_large\n",
    "import math\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = SEBlock(channels, reduction)\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size//2, bias=False),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        spatial_input = torch.cat([avg_out, max_out], dim=1)\n",
    "        spatial_weight = self.spatial_attention(spatial_input)\n",
    "        x = x * spatial_weight\n",
    "        return x\n",
    "\n",
    "class MultiScaleFeatureExtractor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MultiScaleFeatureExtractor, self).__init__()\n",
    "        self.scale1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels // 4, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels // 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.scale2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels // 4, kernel_size=3, padding=1, dilation=1),\n",
    "            nn.BatchNorm2d(out_channels // 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.scale3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels // 4, kernel_size=3, padding=2, dilation=2),\n",
    "            nn.BatchNorm2d(out_channels // 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.scale4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels // 4, kernel_size=3, padding=4, dilation=4),\n",
    "            nn.BatchNorm2d(out_channels // 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale1 = self.scale1(x)\n",
    "        scale2 = self.scale2(x)\n",
    "        scale3 = self.scale3(x)\n",
    "        scale4 = self.scale4(x)\n",
    "        multi_scale = torch.cat([scale1, scale2, scale3, scale4], dim=1)\n",
    "        fused = self.fusion(multi_scale)\n",
    "        return fused\n",
    "\n",
    "class HybridPlantDiseaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=10, backbone='small'):\n",
    "        super(HybridPlantDiseaseModel, self).__init__()\n",
    "        \n",
    "        if backbone == 'small':\n",
    "            self.backbone = mobilenet_v3_small(pretrained=True)\n",
    "            backbone_channels = [16, 24, 40, 96, 576]\n",
    "        else:\n",
    "            self.backbone = mobilenet_v3_large(pretrained=True)\n",
    "            backbone_channels = [16, 24, 40, 112, 960]\n",
    "        \n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.feature_extractors = nn.ModuleList()\n",
    "        \n",
    "        self.ms_extractor_1 = MultiScaleFeatureExtractor(backbone_channels[1], 128)\n",
    "        self.ms_extractor_2 = MultiScaleFeatureExtractor(backbone_channels[2], 256)\n",
    "        self.ms_extractor_3 = MultiScaleFeatureExtractor(backbone_channels[3], 512)\n",
    "        \n",
    "        self.attention_1 = CBAM(128)\n",
    "        self.attention_2 = CBAM(256)\n",
    "        self.attention_3 = CBAM(512)\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        feature_dim = 128 + 256 + 512\n",
    "        \n",
    "        self.feature_fusion = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def _extract_backbone_features(self, x):\n",
    "        features = []\n",
    "        x = self.backbone.features[0](x)\n",
    "        features.append(x)\n",
    "        \n",
    "        for i in range(1, len(self.backbone.features)):\n",
    "            x = self.backbone.features[i](x)\n",
    "            if i in [2, 5, 11]:\n",
    "                features.append(x)\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def forward(self, x):\n",
    "        backbone_features = self._extract_backbone_features(x)\n",
    "        \n",
    "        ms_feat_1 = self.ms_extractor_1(backbone_features[1])\n",
    "        ms_feat_2 = self.ms_extractor_2(backbone_features[2])\n",
    "        ms_feat_3 = self.ms_extractor_3(backbone_features[3])\n",
    "        \n",
    "        att_feat_1 = self.attention_1(ms_feat_1)\n",
    "        att_feat_2 = self.attention_2(ms_feat_2)\n",
    "        att_feat_3 = self.attention_3(ms_feat_3)\n",
    "        \n",
    "        global_feat_1 = self.global_pool(att_feat_1).view(att_feat_1.size(0), -1)\n",
    "        global_feat_2 = self.global_pool(att_feat_2).view(att_feat_2.size(0), -1)\n",
    "        global_feat_3 = self.global_pool(att_feat_3).view(att_feat_3.size(0), -1)\n",
    "        \n",
    "        fused_features = torch.cat([global_feat_1, global_feat_2, global_feat_3], dim=1)\n",
    "        fused_features = self.feature_fusion(fused_features)\n",
    "        \n",
    "        output = self.classifier(fused_features)\n",
    "        return output\n",
    "\n",
    "def get_model_info(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "    \n",
    "model = HybridPlantDiseaseModel(num_classes=cfg.num_classes, backbone='small')\n",
    "model.to(cfg.device)\n",
    "\n",
    "get_model_info(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JfetTMYmb4y3"
   },
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, labels in loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return running_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PkU9bVvob9fu"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = probs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs[:,1].cpu().numpy() if probs.size(1) == 2 else np.max(probs.cpu().numpy(), axis=1))\n",
    "    return (running_loss / total,\n",
    "            correct / total,\n",
    "            np.array(all_labels),\n",
    "            np.array(all_preds),\n",
    "            np.array(all_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fdCZupLub9kK"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, y_prob, average=\"macro\"):\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, average=average, zero_division=0)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    specificity_per_class = []\n",
    "    for i in range(len(cm)):\n",
    "        tp = cm[i,i]\n",
    "        fn = cm[i,:].sum() - tp\n",
    "        fp = cm[:,i].sum() - tp\n",
    "        tn = cm.sum() - (tp + fp + fn)\n",
    "        specificity_per_class.append(tn / (tn + fp + 1e-6))\n",
    "    specificity = np.mean(specificity_per_class)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall (sensitivity)\": rec,\n",
    "        \"specificity\": specificity,\n",
    "        \"f1-score\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qT6dNTFb48A",
    "outputId": "54bdf24a-6cf2-4779-aaee-a23ce65716f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:16<24:17, 76.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " Train Loss: 1.4947 | Train Acc: 0.5902\n",
      " Val   Loss: 1.4664 | Val Acc: 0.6402\n",
      " Metrics: {'accuracy': 0.6401952085181899, 'precision': 0.701335596949097, 'recall (sensitivity)': 0.5908299621224499, 'specificity': 0.9661652734044734, 'f1-score': 0.6059201346496089}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:29<22:24, 74.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      " Train Loss: 1.0815 | Train Acc: 0.7829\n",
      " Val   Loss: 1.0306 | Val Acc: 0.8119\n",
      " Metrics: {'accuracy': 0.8118899733806566, 'precision': 0.8321393953954318, 'recall (sensitivity)': 0.7670881206811476, 'specificity': 0.9823644636034526, 'f1-score': 0.777353188947458}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [03:42<20:54, 73.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      " Train Loss: 0.9404 | Train Acc: 0.8395\n",
      " Val   Loss: 0.9104 | Val Acc: 0.8509\n",
      " Metrics: {'accuracy': 0.8509316770186336, 'precision': 0.8449846681543165, 'recall (sensitivity)': 0.833595578145445, 'specificity': 0.9861812935083206, 'f1-score': 0.8367252278764852}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [04:55<19:34, 73.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      " Train Loss: 0.8455 | Train Acc: 0.8796\n",
      " Val   Loss: 0.8111 | Val Acc: 0.8949\n",
      " Metrics: {'accuracy': 0.8948535936113576, 'precision': 0.8771624720535014, 'recall (sensitivity)': 0.8872569969144002, 'specificity': 0.9903510523001011, 'f1-score': 0.8810028992253592}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [06:08<18:16, 73.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      " Train Loss: 0.7905 | Train Acc: 0.9017\n",
      " Val   Loss: 0.8279 | Val Acc: 0.8824\n",
      " Metrics: {'accuracy': 0.8824312333629104, 'precision': 0.8866331710601935, 'recall (sensitivity)': 0.8684745543347253, 'specificity': 0.9889555089195833, 'f1-score': 0.8742647986721188}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [07:21<17:02, 73.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      " Train Loss: 0.7718 | Train Acc: 0.9112\n",
      " Val   Loss: 0.8355 | Val Acc: 0.8793\n",
      " Metrics: {'accuracy': 0.8793256433007985, 'precision': 0.8831712642384607, 'recall (sensitivity)': 0.8509071884487168, 'specificity': 0.9886572666752262, 'f1-score': 0.8638747777861963}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [08:33<15:48, 73.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      " Train Loss: 0.7235 | Train Acc: 0.9298\n",
      " Val   Loss: 0.7421 | Val Acc: 0.9197\n",
      " Metrics: {'accuracy': 0.919698314108252, 'precision': 0.9147534689633833, 'recall (sensitivity)': 0.906279823559179, 'specificity': 0.9925656235066391, 'f1-score': 0.9075208677924013}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [09:48<14:43, 73.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      " Train Loss: 0.7028 | Train Acc: 0.9394\n",
      " Val   Loss: 0.7348 | Val Acc: 0.9219\n",
      " Metrics: {'accuracy': 0.9219165927240461, 'precision': 0.9235382010265365, 'recall (sensitivity)': 0.9152089083723225, 'specificity': 0.9927112853954906, 'f1-score': 0.9181948444169571}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [11:01<13:27, 73.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      " Train Loss: 0.6929 | Train Acc: 0.9401\n",
      " Val   Loss: 0.7187 | Val Acc: 0.9321\n",
      " Metrics: {'accuracy': 0.9321206743566992, 'precision': 0.9317290873174922, 'recall (sensitivity)': 0.9162947625344878, 'specificity': 0.9935986912641054, 'f1-score': 0.9229282126668884}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [12:14<12:13, 73.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      " Train Loss: 0.6713 | Train Acc: 0.9520\n",
      " Val   Loss: 0.7409 | Val Acc: 0.9232\n",
      " Metrics: {'accuracy': 0.9232475598935226, 'precision': 0.9156431947554292, 'recall (sensitivity)': 0.9072188729899858, 'specificity': 0.9928630856407129, 'f1-score': 0.9095601130789955}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [13:27<10:58, 73.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      " Train Loss: 0.6543 | Train Acc: 0.9568\n",
      " Val   Loss: 0.7239 | Val Acc: 0.9246\n",
      " Metrics: {'accuracy': 0.9245785270629991, 'precision': 0.9281600889627418, 'recall (sensitivity)': 0.914664044785523, 'specificity': 0.9929649177850534, 'f1-score': 0.9191223701085044}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [14:40<09:43, 72.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      " Train Loss: 0.6533 | Train Acc: 0.9590\n",
      " Val   Loss: 0.7805 | Val Acc: 0.9064\n",
      " Metrics: {'accuracy': 0.9063886424134872, 'precision': 0.9151317188274954, 'recall (sensitivity)': 0.8968925203213834, 'specificity': 0.9911404978797401, 'f1-score': 0.9042193350194814}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [15:53<08:31, 73.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      " Train Loss: 0.6455 | Train Acc: 0.9613\n",
      " Val   Loss: 0.7317 | Val Acc: 0.9281\n",
      " Metrics: {'accuracy': 0.9281277728482697, 'precision': 0.9317610594215981, 'recall (sensitivity)': 0.9086757199035488, 'specificity': 0.9932285865968037, 'f1-score': 0.918504216515556}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [17:06<07:18, 73.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      " Train Loss: 0.6492 | Train Acc: 0.9590\n",
      " Val   Loss: 0.7224 | Val Acc: 0.9317\n",
      " Metrics: {'accuracy': 0.9316770186335404, 'precision': 0.9366302482788226, 'recall (sensitivity)': 0.9118990148705722, 'specificity': 0.9935496769699173, 'f1-score': 0.9229929153882813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [18:19<06:04, 72.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      " Train Loss: 0.6309 | Train Acc: 0.9664\n",
      " Val   Loss: 0.6913 | Val Acc: 0.9450\n",
      " Metrics: {'accuracy': 0.9449866903283053, 'precision': 0.9374851132460598, 'recall (sensitivity)': 0.928944582834221, 'specificity': 0.9948512568837257, 'f1-score': 0.9327491648476626}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [19:32<04:52, 73.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      " Train Loss: 0.6393 | Train Acc: 0.9619\n",
      " Val   Loss: 0.7126 | Val Acc: 0.9330\n",
      " Metrics: {'accuracy': 0.9330079858030168, 'precision': 0.9218534787858448, 'recall (sensitivity)': 0.9272816237214836, 'specificity': 0.9937779796284986, 'f1-score': 0.9233105480961776}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [20:46<03:39, 73.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      " Train Loss: 0.6244 | Train Acc: 0.9671\n",
      " Val   Loss: 0.7030 | Val Acc: 0.9348\n",
      " Metrics: {'accuracy': 0.9347826086956522, 'precision': 0.930012562434479, 'recall (sensitivity)': 0.926686295983643, 'specificity': 0.9938770455269729, 'f1-score': 0.9277464665835122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [22:00<02:27, 73.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      " Train Loss: 0.6222 | Train Acc: 0.9696\n",
      " Val   Loss: 0.6875 | Val Acc: 0.9383\n",
      " Metrics: {'accuracy': 0.9383318544809228, 'precision': 0.9384025548333733, 'recall (sensitivity)': 0.9200151555973243, 'specificity': 0.9942422343966055, 'f1-score': 0.927164823757119}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [23:12<01:13, 73.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      " Train Loss: 0.6200 | Train Acc: 0.9690\n",
      " Val   Loss: 0.6853 | Val Acc: 0.9441\n",
      " Metrics: {'accuracy': 0.9440993788819876, 'precision': 0.9342609956554283, 'recall (sensitivity)': 0.9296467899851546, 'specificity': 0.9947775359830415, 'f1-score': 0.9308684607649184}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [24:25<00:00, 73.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      " Train Loss: 0.6112 | Train Acc: 0.9733\n",
      " Val   Loss: 0.6885 | Val Acc: 0.9401\n",
      " Metrics: {'accuracy': 0.9401064773735581, 'precision': 0.9282956590286501, 'recall (sensitivity)': 0.9311637281224724, 'specificity': 0.994429929792325, 'f1-score': 0.9291670428656603}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(cfg.epochs)):\n",
    "    train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, cfg.device)\n",
    "    val_loss, val_acc, y_true, y_pred, y_prob = evaluate(model, val_loader, criterion, cfg.device)\n",
    "    metrics = compute_metrics(y_true, y_pred, y_prob, average=\"macro\")\n",
    "    print(f\"Epoch {epoch+1}/{cfg.epochs}\")\n",
    "    print(f\" Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\" Val   Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(\" Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
